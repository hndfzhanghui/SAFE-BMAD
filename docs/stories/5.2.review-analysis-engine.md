# Story 5.2: 复盘分析引擎

## Status
Draft

## Story

**As a** 复盘分析师,
**I want** 一个智能化的复盘分析引擎,
**so that** 能够基于归档的事件数据进行多维度的深度分析，识别决策效果和改进机会。

## Acceptance Criteria

1. 系统能够进行效果评估分析和决策路径分析
2. 支持多维度对比分析和异常模式识别
3. 提供量化的分析指标和评估结果
4. 支持自定义分析维度和评估标准

## Tasks / Subtasks

- [ ] 实现效果评估分析模块 (AC: #1)
  - [ ] 设计效果评估框架
    - [ ] 评估指标体系设计
    - [ ] 评估算法选择
    - [ ] 评估模型构建
    - [ ] 评估结果验证器
  - [ ] 实现决策效果分析器
    - [ ] 决策执行结果分析
    - [ ] 目标达成度评估
    - [ ] 效果偏差分析
    - [ ] 效果改进建议
  - [ ] 创建智能体性能评估
    - [ ] S-Agent战略分析效果评估
    - [ ] A-Agent态势感知准确性评估
    - [ ] F-Agent专业建议有效性评估
    - [ ] E-Agent方案执行效果评估
  - [ ] 实现时间维度分析
    - [ ] 决策响应时间分析
    - [ ] 执行效率时间评估
    - [ ] 时序关联性分析
    - [ ] 时间优化建议
  - [ ] 设计效果对比分析
    - [ ] 不同方案效果对比
    - [ ] 历史案例对比
    - [ ] 理想效果对比
    - [ ] 改进空间分析

- [ ] 实现决策路径分析模块 (AC: #2)
  - [ ] 设计决策路径追踪器
    - [ ] 决策节点识别
    - [ ] 路径构建算法
    - [ ] 路径优化分析
    - [ ] 路径可视化器
  - [ ] 实现决策影响分析
    - [ ] 前置决策影响分析
    - [ ] 后置决策效果分析
    - [ ] 决策关联性评估
    - [ ] 影响范围计算
  - [ ] 创建决策质量评估
    - [ ] 决策逻辑一致性评估
    - [ ] 决策依据充分性评估
    - [ ] 决策时效性评估
    - [ ] 决策风险评估
  - [ ] 实现决策模式识别
    - [ ] 决策模式分类器
    - [ ] 模式特征提取
    - [ ] 模式效果分析
    - [ ] 模式优化建议
  - [ ] 设计决策优化建议
    - [ ] 决策流程优化
    - [ ] 决策工具改进
    - [ ] 决策支持增强
    - [ ] 决策培训建议

- [ ] 实现多维度对比分析模块 (AC: #3)
  - [ ] 设计对比分析框架
    - [ ] 对比维度定义
    - [ ] 对比指标体系
    - [ ] 对比方法选择
    - [ ] 对比结果解释
  - [ ] 实现横向对比分析
    - [ ] 同类事件对比
    - [ ] 不同策略对比
    - [ ] 资源配置对比
    - [ ] 结果效果对比
  - [ ] 创建纵向对比分析
    - [ ] 历史演进对比
    - [ ] 时间序列对比
    - [ ] 阶段性进展对比
    - [ ] 成长趋势分析
  - [ ] 实现场景对比分析
    - [ ] 模拟场景对比
    - [ ] 实际执行对比
    - [ ] 假设验证对比
    - [ ] 场景适配分析
  - [ ] 设计对比可视化
    - [ ] 对比图表生成
    - [ ] 差异可视化
    - [ ] 趋势可视化
    - [ ] 交互式对比界面
  - [ ] 实现对比报告生成
    - [ ] 对比分析报告
    - [ ] 差异分析报告
    - [ ] 改进建议报告
    - [ ] 经验总结报告

- [ ] 实现异常模式识别模块 (AC: #4)
  - [ ] 设计异常检测算法
    - [ ] 统计异常检测
    - [ ] 机器学习异常检测
    - [ ] 时序异常检测
    - [ ] 关联异常检测
  - [ ] 实现模式识别引擎
    - [ ] 异常模式分类器
    - [ ] 模式特征提取
    - [ ] 模式频率分析
    - [ ] 模式影响评估
  - [ ] 创建预测分析功能
    - [ ] 异常趋势预测
    - [ ] 风险预警模型
    - [ ] 改进效果预测
    - [ ] 预测准确性验证
  - [ ] 实现知识图谱分析
    - [ ] 关联关系图谱
    - [ ] 异常传播路径
    - [ ] 知识依赖分析
    - [ ] 知识图谱可视化
  - [ ] 设计异常处理建议
    - [ ] 异常处理策略
    - [ ] 预防措施建议
    - [ ] 应急预案优化
    - [ ] 系统改进建议

- [ ] 实现分析结果管理系统 (AC: #5)
  - [ ] 设计分析结果存储
    - [ ] 结果数据模型
    - [ ] 结果版本管理
    - [ ] 结果查询接口
    - [ ] 结果共享机制
  - [ ] 实现分析报告生成
    - [ ] 自动报告生成器
    - [ ] 报告模板管理
    - [ ] 报告内容填充
    - [ ] 报告质量控制
  - [ ] 创建分析仪表板
    - [ ] 实时分析展示
    - [ ] 关键指标监控
    - [ ] 趋势分析展示
    - [ ] 交互式探索功能
  - [ ] 实现分析知识库
    - [ ] 分析方法库管理
    - [ ] 经验案例库
    - [ ] 最佳实践库
    - [ ] 知识更新机制
  - [ ] 设计协作分析功能
    - [ ] 多用户协作分析
    - [ ] 分析权限管理
    - [ ] 分析过程记录
    - [ ] 协作结果整合

## Dev Notes

### 技术架构信息
复盘分析引擎采用以下技术栈：
- 分析框架: Apache Spark + Dask (分布式计算)
- 机器学习: Scikit-learn + XGBoost + LightGBM
- 图分析: NetworkX + Neo4j
- 数据可视化: Plotly + D3.js + Matplotlib
- 统计分析: SciPy + Statsmodels
- 时序分析: Prophet + ARIMA + LSTM

### 核心设计架构
```python
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
import json
import asyncio
import time
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from abc import ABC, abstractmethod
import logging
import networkx as nx
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.cluster import DBSCAN

class AnalysisType(Enum):
    """分析类型枚举"""
    EFFECTIVENESS = "effectiveness"
    DECISION_PATH = "decision_path"
    COMPARATIVE = "comparative"
    ANOMALY_DETECTION = "anomaly_detection"
    PERFORMANCE = "performance"

class EvaluationLevel(Enum):
    """评估等级枚举"""
    EXCELLENT = 5
    GOOD = 4
    SATISFACTORY = 3
    POOR = 2
    UNSATISFACTORY = 1

@dataclass
class AnalysisResult:
    """分析结果数据模型"""
    analysis_id: str
    event_id: str
    analysis_type: AnalysisType
    analysis_timestamp: datetime

    # 分析内容
    metrics: Dict[str, float]
    insights: List[str]
    recommendations: List[Dict[str, Any]]

    # 评估结果
    overall_score: float
    evaluation_level: EvaluationLevel
    confidence_level: float

    # 元数据
    methodology: str
    assumptions: List[str]
    limitations: List[str]

    # 关联数据
    supporting_evidence: List[Dict[str, Any]]
    related_analyses: List[str]

@dataclass
class DecisionPath:
    """决策路径数据模型"""
    path_id: str
    event_id: str

    # 路径结构
    decision_nodes: List[Dict[str, Any]]
    connections: List[Tuple[str, str]]
    timeline: List[Dict[str, Any]]

    # 路径分析
    path_effectiveness: float
    decision_quality: float
    execution_efficiency: float

    # 影响分析
    upstream_factors: List[str]
    downstream_effects: List[str]
    critical_decisions: List[str]

    # 优化建议
    improvement_opportunities: List[Dict[str, Any]]
    alternative_paths: List[Dict[str, Any]]

class ReviewAnalysisEngine:
    """复盘分析引擎"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config

        # 分析组件
        self.effectiveness_analyzer = EffectivenessAnalyzer()
        self.decision_path_analyzer = DecisionPathAnalyzer()
        self.comparative_analyzer = ComparativeAnalyzer()
        self.anomaly_detector = AnomalyDetector()
        self.performance_analyzer = PerformanceAnalyzer()

        # 数据处理组件
        self.data_processor = DataProcessor()
        self.feature_extractor = FeatureExtractor()
        self.model_trainer = ModelTrainer()

        # 结果管理组件
        self.result_manager = ResultManager()
        self.report_generator = ReportGenerator()
        self.knowledge_manager = KnowledgeManager()

    async def analyze_event(self, event_id: str,
                           analysis_types: List[AnalysisType] = None) -> Dict[str, Any]:
        """分析事件"""
        start_time = time.time()

        try:
            # 确定分析类型
            if analysis_types is None:
                analysis_types = [
                    AnalysisType.EFFECTIVENESS,
                    AnalysisType.DECISION_PATH,
                    AnalysisType.COMPARATIVE,
                    AnalysisType.ANOMALY_DETECTION
                ]

            # 加载事件数据
            event_data = await self.data_processor.load_event_data(event_id)

            # 数据预处理
            processed_data = await self.data_processor.preprocess_data(event_data)

            # 特征提取
            features = await self.feature_extractor.extract_features(processed_data)

            analysis_results = {}

            # 执行各类分析
            for analysis_type in analysis_types:
                try:
                    result = await self._execute_analysis(
                        analysis_type, event_id, processed_data, features
                    )
                    analysis_results[analysis_type.value] = result
                except Exception as e:
                    logger.error(f"Failed to execute {analysis_type.value} analysis: {e}")
                    continue

            # 生成综合分析报告
            comprehensive_report = await self._generate_comprehensive_report(
                event_id, analysis_results
            )

            # 存储分析结果
            await self.result_manager.store_analysis_results(
                event_id, analysis_results, comprehensive_report
            )

            # 更新知识库
            await self.knowledge_manager.update_knowledge_base(
                event_id, analysis_results
            )

            result = {
                'event_id': event_id,
                'analysis_results': analysis_results,
                'comprehensive_report': comprehensive_report,
                'analysis_time': time.time() - start_time,
                'analysis_types_used': [t.value for t in analysis_types],
                'data_summary': {
                    'total_records': len(processed_data),
                    'feature_count': len(features),
                    'analysis_start_time': start_time
                }
            }

            return result

        except Exception as e:
            logger.error(f"Failed to analyze event {event_id}: {e}")
            raise

    async def _execute_analysis(self, analysis_type: AnalysisType,
                                event_id: str,
                                processed_data: pd.DataFrame,
                                features: Dict[str, Any]) -> AnalysisResult:
        """执行特定类型的分析"""
        try:
            if analysis_type == AnalysisType.EFFECTIVENESS:
                return await self.effectiveness_analyzer.analyze(
                    event_id, processed_data, features
                )
            elif analysis_type == AnalysisType.DECISION_PATH:
                return await self.decision_path_analyzer.analyze(
                    event_id, processed_data, features
                )
            elif analysis_type == AnalysisType.COMPARATIVE:
                return await self.comparative_analyzer.analyze(
                    event_id, processed_data, features
                )
            elif analysis_type == AnalysisType.ANOMALY_DETECTION:
                return await self.anomaly_detector.analyze(
                    event_id, processed_data, features
                )
            elif analysis_type == AnalysisType.PERFORMANCE:
                return await self.performance_analyzer.analyze(
                    event_id, processed_data, features
                )
            else:
                raise ValueError(f"Unsupported analysis type: {analysis_type}")

        except Exception as e:
            logger.error(f"Failed to execute {analysis_type.value} analysis: {e}")
            raise

    async def _generate_comprehensive_report(self,
                                          event_id: str,
                                          analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """生成综合分析报告"""
        try:
            # 综合所有分析结果
            overall_metrics = {}
            all_insights = []
            all_recommendations = []

            for analysis_type, result in analysis_results.items():
                overall_metrics.update(result.metrics)
                all_insights.extend(result.insights)
                all_recommendations.extend(result.recommendations)

            # 计算综合评分
            overall_score = np.mean([
                result.overall_score for result in analysis_results.values()
            ])

            # 确定综合评估等级
            if overall_score >= 0.8:
                evaluation_level = EvaluationLevel.EXCELLENT
            elif overall_score >= 0.6:
                evaluation_level = EvaluationLevel.GOOD
            elif overall_score >= 0.4:
                evaluation_level = EvaluationLevel.SATISFACTORY
            elif overall_score >= 0.2:
                evaluation_level = EvaluationLevel.POOR
            else:
                evaluation_level = EvaluationLevel.UNSATISFACTORY

            comprehensive_report = {
                'event_id': event_id,
                'analysis_timestamp': datetime.now().isoformat(),
                'overall_metrics': overall_metrics,
                'key_insights': all_insights,
                'top_recommendations': sorted(
                    all_recommendations,
                    key=lambda x: x.get('priority', 0),
                    reverse=True
                )[:10],
                'overall_evaluation': {
                    'score': overall_score,
                    'level': evaluation_level.value,
                    'confidence': np.mean([
                        result.confidence_level for result in analysis_results.values()
                    ])
                },
                'analysis_summary': {
                    'total_analyses': len(analysis_results),
                    'analysis_types': list(analysis_results.keys()),
                    'data_quality': await self._assess_data_quality(analysis_results),
                    'analysis_coverage': await self._assess_analysis_coverage(analysis_results)
                }
            }

            return comprehensive_report

        except Exception as e:
            logger.error(f"Failed to generate comprehensive report: {e}")
            raise

class EffectivenessAnalyzer:
    """效果评估分析器"""

    def __init__(self):
        self.effectiveness_metrics = {
            'goal_achievement': GoalAchievementMetric(),
            'resource_efficiency': ResourceEfficiencyMetric(),
            'response_time': ResponseTimeMetric(),
            'decision_accuracy': DecisionAccuracyMetric()
        }

    async def analyze(self, event_id: str,
                     processed_data: pd.DataFrame,
                     features: Dict[str, Any]) -> AnalysisResult:
        """执行效果评估分析"""
        try:
            # 目标达成度评估
            goal_achievement = await self.effectiveness_metrics['goal_achievement'].evaluate(
                processed_data, features
            )

            # 资源效率评估
            resource_efficiency = await self.effectiveness_metrics['resource_efficiency'].evaluate(
                processed_data, features
            )

            # 响应时间评估
            response_time = await self.effectiveness_metrics['response_time'].evaluate(
                processed_data, features
            )

            # 决策准确性评估
            decision_accuracy = await self.effectiveness_metrics['decision_accuracy'].evaluate(
                processed_data, features
            )

            # 计算综合效果评分
            metrics = {
                'goal_achievement': goal_achievement,
                'resource_efficiency': resource_efficiency,
                'response_time': response_time,
                'decision_accuracy': decision_accuracy
            }

            overall_score = np.mean(list(metrics.values()))

            # 生成洞察和建议
            insights = await self._generate_effectiveness_insights(metrics)
            recommendations = await self._generate_effectiveness_recommendations(metrics)

            result = AnalysisResult(
                analysis_id=f"effectiveness_{event_id}_{int(time.time())}",
                event_id=event_id,
                analysis_type=AnalysisType.EFFECTIVENESS,
                analysis_timestamp=datetime.now(),
                metrics=metrics,
                insights=insights,
                recommendations=recommendations,
                overall_score=overall_score,
                evaluation_level=self._determine_evaluation_level(overall_score),
                confidence_level=0.85,  # 基于数据质量和分析方法的置信度
                methodology="多维度效果评估算法",
                assumptions=[
                    "目标定义明确且可衡量",
                    "资源记录完整准确",
                    "时间戳准确一致",
                    "决策结果可验证"
                ],
                limitations=[
                    "评估结果依赖于历史数据的完整性",
                    "部分效果指标可能难以量化",
                    "外部环境因素可能影响结果"
                ],
                supporting_evidence=[],
                related_analyses=[]
            )

            return result

        except Exception as e:
            logger.error(f"Failed to perform effectiveness analysis: {e}")
            raise

    def _determine_evaluation_level(self, score: float) -> EvaluationLevel:
        """确定评估等级"""
        if score >= 0.8:
            return EvaluationLevel.EXCELLENT
        elif score >= 0.6:
            return EvaluationLevel.GOOD
        elif score >= 0.4:
            return EvaluationLevel.SATISFACTORY
        elif score >= 0.2:
            return EvaluationLevel.POOR
        else:
            return EvaluationLevel.UNSATISFACTORY

class DecisionPathAnalyzer:
    """决策路径分析器"""

    def __init__(self):
        self.path_builder = PathBuilder()
        self.path_evaluator = PathEvaluator()
        self.path_optimizer = PathOptimizer()

    async def analyze(self, event_id: str,
                     processed_data: pd.DataFrame,
                     features: Dict[str, Any]) -> AnalysisResult:
        """执行决策路径分析"""
        try:
            # 构建决策路径
            decision_path = await self.path_builder.build_path(
                event_id, processed_data, features
            )

            # 评估路径效果
            path_evaluation = await self.path_evaluator.evaluate_path(decision_path)

            # 优化建议
            optimization_suggestions = await self.path_optimizer.optimize_path(
                decision_path, path_evaluation
            )

            metrics = {
                'path_effectiveness': path_evaluation.effectiveness,
                'decision_quality': path_evaluation.quality_score,
                'execution_efficiency': path_evaluation.efficiency,
                'path_complexity': path_evaluation.complexity_score,
                'decision_count': len(decision_path.decision_nodes)
            }

            overall_score = path_evaluation.effectiveness

            insights = [
                f"决策路径包含{len(decision_path.decision_nodes)}个关键决策点",
                f"路径整体效果评分: {overall_score:.2f}",
                f"关键决策: {', '.join(path_evaluation.critical_decisions[:3])}"
            ]

            recommendations = optimization_suggestions

            result = AnalysisResult(
                analysis_id=f"decision_path_{event_id}_{int(time.time())}",
                event_id=event_id,
                analysis_type=AnalysisType.DECISION_PATH,
                analysis_timestamp=datetime.now(),
                metrics=metrics,
                insights=insights,
                recommendations=recommendations,
                overall_score=overall_score,
                evaluation_level=self._determine_evaluation_level(overall_score),
                confidence_level=0.80,
                methodology="决策路径构建与评估算法",
                assumptions=[
                    "决策记录完整准确",
                    "决策时间戳正确",
                    "决策因果关系明确"
                ],
                limitations=[
                    "路径构建依赖于决策记录的完整性",
                    "复杂决策路径可能难以完全重构",
                    "部分决策影响可能难以量化"
                ],
                supporting_evidence=[],
                related_analyses=[]
            )

            return result

        except Exception as e:
            logger.error(f"Failed to perform decision path analysis: {e}")
            raise

class AnomalyDetector:
    """异常模式识别器"""

    def __init__(self):
        self.statistical_detector = StatisticalAnomalyDetector()
        self.ml_detector = MLAnomalyDetector()
        self.pattern_recognizer = PatternRecognizer()

    async def analyze(self, event_id: str,
                     processed_data: pd.DataFrame,
                     features: Dict[str, Any]) -> AnalysisResult:
        """执行异常模式识别"""
        try:
            # 统计异常检测
            statistical_anomalies = await self.statistical_detector.detect(
                processed_data, features
            )

            # 机器学习异常检测
            ml_anomalies = await self.ml_detector.detect(
                processed_data, features
            )

            # 模式识别
            anomaly_patterns = await self.pattern_recognizer.recognize_patterns(
                statistical_anomalies, ml_anomalies
            )

            # 合并异常检测结果
            all_anomalies = statistical_anomalies + ml_anomalies

            metrics = {
                'anomaly_count': len(all_anomalies),
                'statistical_anomalies': len(statistical_anomalies),
                'ml_anomalies': len(ml_anomalies),
                'pattern_count': len(anomaly_patterns),
                'anomaly_severity': self._calculate_anomaly_severity(all_anomalies)
            }

            # 基于异常数量计算评分（异常越少越好）
            if len(all_anomalies) == 0:
                overall_score = 1.0
            elif len(all_anomalies) <= 5:
                overall_score = 0.8
            elif len(all_anomalies) <= 10:
                overall_score = 0.6
            else:
                overall_score = 0.4

            insights = [
                f"检测到{len(all_anomalies)}个异常模式",
                f"识别出{len(anomaly_patterns)}种异常类型",
                f"异常严重程度: {metrics['anomaly_severity']:.2f}"
            ]

            recommendations = await self._generate_anomaly_recommendations(
                all_anomalies, anomaly_patterns
            )

            result = AnalysisResult(
                analysis_id=f"anomaly_detection_{event_id}_{int(time.time())}",
                event_id=event_id,
                analysis_type=AnalysisType.ANOMALY_DETECTION,
                analysis_timestamp=datetime.now(),
                metrics=metrics,
                insights=insights,
                recommendations=recommendations,
                overall_score=overall_score,
                evaluation_level=self._determine_evaluation_level(overall_score),
                confidence_level=0.75,
                methodology="多方法异常检测算法",
                assumptions=[
                    "数据质量良好",
                    "异常模式具有可识别特征",
                    "训练数据具有代表性"
                ],
                limitations=[
                    "异常检测可能存在误报",
                    "新型异常模式可能无法识别",
                    "异常检测结果需要人工验证"
                ],
                supporting_evidence=[],
                related_analyses=[]
            )

            return result

        except Exception as e:
            logger.error(f"Failed to perform anomaly detection: {e}")
            raise
```

### 开发工作流程
1. 设计效果评估框架和决策路径分析器
2. 实现多维度对比分析和异常检测算法
3. 开发分析结果管理和报告生成系统
4. 构建分析知识库和协作分析功能
5. 集成数据处理和特征提取组件
6. 实现性能优化和扩展性设计
7. 建立分析质量控制和验证机制
8. 进行全面测试和性能调优

### 依赖关系说明
- 依赖Story 5.1完成的事件数据归档系统
- 需要高质量的归档数据作为分析基础
- 为Story 5.3经验学习系统提供分析结果
- 为整个R-Agent系统提供核心分析能力

### 重要注意事项
- 分析算法需要考虑多维度的综合评估
- 决策路径分析需要处理复杂的因果关系
- 异常检测需要平衡准确性和误报率
- 对比分析需要考虑数据的可比性
- 分析结果需要具有可解释性和可操作性

### 测试策略
- 单元测试: 测试各分析算法的准确性
- 集成测试: 测试完整的分析流程
- 算法测试: 验证机器学习模型的效果
- 性能测试: 测试大数据量的分析性能
- 准确性测试: 验证分析结果的可信度

### Testing

#### 测试标准
- 测试文件位置: tests/analysis/目录
- 效果评估测试: 验证评估算法的准确性
- 决策路径测试: 验证路径构建和评估
- 异常检测测试: 验证异常识别的准确性
- 对比分析测试: 验证对比分析的客观性

#### 测试框架和模式
- 单元测试: pytest + sklearn.testing
- 算法测试: pytest + mock数据
- 性能测试: pytest + pytest-benchmark
- 可视化测试: matplotlib + plotly
- 数据质量测试: 自定义质量评估工具

#### 特定测试要求
- 多维度评估算法的一致性测试
- 复杂决策路径的构建准确性测试
- 异常检测算法的鲁棒性测试
- 大数据量分析的性能测试
- 分析结果可解释性的验证测试

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-10-20 | 1.0 | 初始故事创建 | John (PM) |

## Dev Agent Record

### Agent Model Used
(待开发时填写)

### Debug Log References
(待开发时填写)

### Completion Notes List
(待开发时填写)

### File List
(待开发时填写)

## QA Results
(待QA测试时填写)