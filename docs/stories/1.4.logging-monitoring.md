# Story 1.4: 基础日志和监控系统

## Status
Draft

## Story

**As a** 运维工程师,
**I want** 拥有基础的日志记录和系统监控,
**so that** 及时发现和解决问题。

## Acceptance Criteria

1. 结构化日志记录系统(loguru/structlog)
2. 系统健康检查接口(/health, /ready)
3. 基础性能监控(响应时间、错误率、资源使用)
4. 日志轮转和存储配置
5. 基础告警机制(邮件/企业微信)

## Tasks / Subtasks

- [ ] 实现结构化日志记录系统 (AC: #1)
  - [ ] 选择日志框架和配置
    - [ ] 使用loguru作为主要日志框架
    - [ ] 配置structlog作为备选方案
    - [ ] 创建日志配置文件
    - [   配置不同环境的日志级别
  - [ ] 设计日志格式和结构
    - [   定义标准日志字段(timestamp, level, message, module等)
    - [   添加请求追踪ID
    - [   添加用户信息和上下文
    - [   配置JSON格式输出
  - [ ] 创建日志记录中间件
    - [   FastAPI日志中间件
    - [   请求/响应日志记录
    - [   异常捕获和记录
    - [   性能指标记录
  - [ ] 配置多环境日志
    - [   开发环境日志配置
    - [   测试环境日志配置
    - [   生产环境日志配置
  - [ ] 实现日志工具类
    - [   封装常用日志方法
    - [   支持异步日志记录
    - [   支持日志采样和过滤

- [ ] 实现系统健康检查接口 (AC: #2)
  - [ ] 创建健康检查端点
    - [   GET /health - 基础健康检查
    - [   GET /ready - 就绪状态检查
    - [   GET /live - 存活状态检查
    - [   GET /metrics - 基础指标
  - [ ] 实现健康检查逻辑
    - [   数据库连接检查
    - [   Redis连接检查
    - [   外部服务依赖检查
    - [   系统资源检查
  - [ ] 配置健康检查响应格式
    - [   标准化响应结构
    - [   包含详细状态信息
    - [   包含检查时间戳
    - [   包含服务版本信息
  - [ ] 实现健康检查缓存
    - [   避免频繁检查造成的性能问题
    - [   配置检查间隔
    - [   实现缓存失效机制
  - [ ] 创建健康检查文档
    - [   docs/health-check.md - 使用说明
    - [   集成配置指南

- [ ] 实现基础性能监控 (AC: #3)
  - [ ] 选择监控指标收集方案
    - [   使用Prometheus客户端库
    - [   配置自定义指标
    - [   设置指标标签和维度
  - [ ] 实现API性能监控
    - [   请求响应时间监控
    - [   请求速率监控
    - [   错误率监控
    - [   并发连接数监控
  - [ ] 实现系统资源监控
    - [   CPU使用率监控
    - [   内存使用率监控
    - [   磁盘I/O监控
    - [   网络I/O监控
  - [   实现业务指标监控
    - [   Agent处理时间监控
    - [   数据库查询性能监控
    - [   缓存命中率监控
    - [   用户活跃度监控
  - [ ] 配置指标暴露端点
    - [   GET /metrics - Prometheus指标
    - [   指标格式化输出
    - [   指标标签规范化

- [ ] 配置日志轮转和存储 (AC: #4)
  - [ ] 配置日志轮转策略
    - [   按时间轮转(daily/weekly)
    - [   按大小轮转(max size)
    - [   保留策略(retention)
    - [   压缩策略(compression)
  - [ ] 配置日志存储
    - [   本地文件存储配置
    - [   日志目录结构
    - [   文件权限配置
    - [   存储空间监控
  - [ ] 实现日志归档机制
    - [   自动归档策略
    - [   归档文件命名规则
    - [   归档位置配置
    - [   归档清理机制
  - [ ] 配置Docker环境日志
    - [   容器日志驱动配置
    - [   日志收集配置
    - [   日志转发配置
    - [   日志聚合配置
  - [ ] 创建日志管理脚本
    - [   logs/rotate.sh - 日志轮转脚本
    - [   logs/cleanup.sh - 日志清理脚本
    - [   logs/archive.sh - 日志归档脚本

- [ ] 实现基础告警机制 (AC: #5)
  - [ ] 选择告警通知渠道
    - [   邮件告警配置
    - [   企业微信告警配置
    - [   钉钉告警配置(可选)
    - [   Slack告警配置(可选)
  - [ ] 实现告警规则引擎
    - [   阈值告警规则
    - [   趋势告警规则
    - [   异常检测告警
    - [   自定义告警规则
  - [ ] 创建告警管理模块
    - [   告警规则配置
    - [   告警级别管理
    - [   告警抑制机制
    - [   告警升级机制
  - [ ] 实现告警通知服务
    - [   邮件通知服务
    - [   即时消息通知服务
    - [   短信通知服务(可选)
    - [   告警通知模板
  - [ ] 配置告警测试
    - [   告警测试脚本
    - [   告警模拟器
    - [   告警通知测试
    - [   告警恢复测试

## Dev Notes

### 技术架构信息
日志和监控系统采用现代化技术栈：
- 日志框架: loguru (主要) + structlog (备选)
- 监控指标: Prometheus + prometheus-client
- 健康检查: FastAPI内置功能 + 自定义检查
- 告警通知: 自定义告警引擎 + 多渠道通知
- 日志存储: 本地文件 + 可选ELK集成

### 日志配置示例
```python
# app/core/logging.py
import sys
from pathlib import Path
from loguru import logger
import structlog

def setup_logging():
    # 移除默认handler
    logger.remove()

    # 添加控制台输出
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | "
               "<level>{level: <8}</level> | "
               "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - "
               "<level>{message}</level>",
        level="INFO"
    )

    # 添加文件输出
    logger.add(
        "logs/app.log",
        rotation="10 MB",
        retention="30 days",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
        level="DEBUG"
    )

    # 添加错误日志文件
    logger.add(
        "logs/error.log",
        rotation="10 MB",
        retention="30 days",
        level="ERROR",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}"
    )

def get_logger(name: str):
    return logger.bind(name=name)

# structlog配置
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)
```

### 健康检查实现示例
```python
# api/v1/endpoints/health.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from app.api.deps import get_db
from app.core.config import settings
from app.db.database import get_db_session
import redis
import time

router = APIRouter()

@router.get("/health")
async def health_check():
    """基础健康检查"""
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "version": settings.PROJECT_NAME,
        "environment": settings.ENVIRONMENT
    }

@router.get("/ready")
async def readiness_check(db: Session = Depends(get_db)):
    """就绪状态检查"""
    checks = {}

    # 数据库连接检查
    try:
        db.execute("SELECT 1")
        checks["database"] = "healthy"
    except Exception as e:
        checks["database"] = f"unhealthy: {str(e)}"
        raise HTTPException(status_code=503, detail="Service not ready")

    # Redis连接检查
    try:
        redis_client = redis.Redis.from_url(settings.REDIS_URL)
        redis_client.ping()
        checks["redis"] = "healthy"
    except Exception as e:
        checks["redis"] = f"unhealthy: {str(e)}"
        raise HTTPException(status_code=503, detail="Service not ready")

    return {
        "status": "ready",
        "timestamp": time.time(),
        "checks": checks
    }

@router.get("/live")
async def liveness_check():
    """存活状态检查"""
    return {
        "status": "alive",
        "timestamp": time.time(),
        "uptime": time.time() - start_time
    }
```

### 性能监控实现示例
```python
# app/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge, generate_latest
import time
import functools

# 定义指标
REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status_code']
)

REQUEST_DURATION = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

ACTIVE_CONNECTIONS = Gauge(
    'active_connections',
    'Active connections'
)

CPU_USAGE = Gauge(
    'cpu_usage_percent',
    'CPU usage percentage'
)

MEMORY_USAGE = Gauge(
    'memory_usage_bytes',
    'Memory usage in bytes'
)

def track_requests(func):
    """装饰器：跟踪请求指标"""
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()

        try:
            result = await func(*args, **kwargs)
            REQUEST_COUNT.labels(
                method=kwargs.get('method', 'unknown'),
                endpoint=kwargs.get('endpoint', 'unknown'),
                status_code=200
            ).inc()
            return result
        except Exception as e:
            REQUEST_COUNT.labels(
                method=kwargs.get('method', 'unknown'),
                endpoint=kwargs.get('endpoint', 'unknown'),
                status_code=500
            ).inc()
            raise
        finally:
            REQUEST_DURATION.labels(
                method=kwargs.get('method', 'unknown'),
                endpoint=kwargs.get('endpoint', 'unknown')
            ).observe(time.time() - start_time)

    return wrapper
```

### 告警系统实现示例
```python
# app/alerting/alert_manager.py
import smtplib
import requests
from email.mime.text import MimeText
from email.mime.multipart import MimeMultipart
from typing import List, Dict, Any
from dataclasses import dataclass
from enum import Enum

class AlertLevel(Enum):
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

@dataclass
class Alert:
    level: AlertLevel
    title: str
    message: str
    source: str
    timestamp: float
    metadata: Dict[str, Any] = None

class AlertManager:
    def __init__(self):
        self.email_config = None
        self.wechat_config = None
        self.alert_rules = []

    def send_email_alert(self, alert: Alert):
        """发送邮件告警"""
        if not self.email_config:
            return

        msg = MimeMultipart()
        msg['From'] = self.email_config['from']
        msg['To'] = ', '.join(self.email_config['to'])
        msg['Subject'] = f"[{alert.level.value.upper()}] {alert.title}"

        body = f"""
        告警级别: {alert.level.value}
        告警标题: {alert.title}
        告警消息: {alert.message}
        告警源: {alert.source}
        告警时间: {alert.timestamp}

        元数据:
        {alert.metadata or {}}
        """

        msg.attach(MimeText(body, 'plain'))

        try:
            server = smtplib.SMTP(self.email_config['smtp_server'], self.email_config['smtp_port'])
            server.starttls()
            server.login(self.email_config['username'], self.email_config['password'])
            server.send_message(msg)
            server.quit()
        except Exception as e:
            print(f"Failed to send email alert: {e}")

    def send_wechat_alert(self, alert: Alert):
        """发送企业微信告警"""
        if not self.wechat_config:
            return

        webhook_url = self.wechat_config['webhook_url']

        message = {
            "msgtype": "text",
            "text": {
                "content": f"🚨 {alert.level.value.upper()} 告警\n\n"
                        f"标题: {alert.title}\n"
                        f"消息: {alert.message}\n"
                        f"来源: {alert.source}\n"
                        f"时间: {alert.timestamp}"
            }
        }

        try:
            response = requests.post(webhook_url, json=message, timeout=10)
            response.raise_for_status()
        except Exception as e:
            print(f"Failed to send WeChat alert: {e}")

    def send_alert(self, alert: Alert):
        """发送告警"""
        # 根据告警级别选择发送渠道
        if alert.level in [AlertLevel.ERROR, AlertLevel.CRITICAL]:
            self.send_email_alert(alert)
            self.send_wechat_alert(alert)
        elif alert.level == AlertLevel.WARNING:
            self.send_wechat_alert(alert)
        # INFO级别不发送告警
```

### 日志轮转配置示例
```yaml
# docker-compose.yml 日志配置
version: '3.8'
services:
  api:
    build: .
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=api,environment=dev"
    volumes:
      - ./logs:/app/logs
    environment:
      - LOG_LEVEL=INFO
      - LOG_FILE=/app/logs/app.log

  db:
    image: postgres:14
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
```

### 监控配置示例
```python
# app/monitoring/middleware.py
import time
import uuid
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware

class LoggingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        # 生成请求ID
        request_id = str(uuid.uuid4())
        request.state.request_id = request_id

        # 记录请求开始时间
        start_time = time.time()

        # 记录请求信息
        logger.info(
            f"Request started",
            extra={
                "request_id": request_id,
                "method": request.method,
                "url": str(request.url),
                "client_ip": request.client.host,
                "user_agent": request.headers.get("user-agent")
            }
        )

        try:
            # 处理请求
            response = await call_next(request)

            # 记录响应信息
            process_time = time.time() - start_time
            logger.info(
                f"Request completed",
                extra={
                    "request_id": request_id,
                    "status_code": response.status_code,
                    "process_time": process_time
                }
            )

            # 添加响应头
            response.headers["X-Request-ID"] = request_id
            response.headers["X-Process-Time"] = str(process_time)

            return response

        except Exception as e:
            # 记录错误信息
            process_time = time.time() - start_time
            logger.error(
                f"Request failed",
                extra={
                    "request_id": request_id,
                    "error": str(e),
                    "process_time": process_time
                },
                exc_info=True
            )
            raise
```

### 开发工作流程
1. 配置日志框架和格式
2. 实现健康检查端点
3. 集成性能监控指标
4. 配置日志轮转和存储
5. 实现告警通知机制
6. 测试所有监控功能
7. 配置监控仪表板

### 依赖关系说明
- 依赖Story 1.1完成的项目结构
- 依赖Story 1.2完成的开发环境
- 依赖Story 1.3完成的API框架
- 为后续系统运维提供监控基础

### 重要注意事项
- 日志记录需要注意敏感信息保护
- 监控指标需要考虑性能影响
- 告警通知需要避免告警风暴
- 健康检查需要轻量级设计
- 日志存储需要考虑磁盘空间

### 监控指标建议
- API响应时间: < 200ms (P95)
- 错误率: < 1%
- CPU使用率: < 80%
- 内存使用率: < 85%
- 磁盘使用率: < 90%

### Testing

#### 测试标准
- 测试文件位置: tests/monitoring/目录
- 日志功能测试: 验证日志格式和输出
- 健康检查测试: 验证各种状态检查
- 监控指标测试: 验证指标收集和格式
- 告警功能测试: 验证告警发送和格式

#### 测试框架和模式
- 日志测试: pytest + caplog
- API测试: pytest + TestClient
- 监控测试: pytest + prometheus-client
- 告警测试: pytest + mock

#### 特定测试要求
- 所有日志级别需要测试
- 健康检查异常情况需要测试
- 监控指标准确性需要验证
- 告警通知需要实际发送测试(使用测试渠道)

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-10-20 | 1.0 | 初始故事创建 | John (PM) |

## Dev Agent Record

### Agent Model Used
(待开发时填写)

### Debug Log References
(待开发时填写)

### Completion Notes List
(待开发时填写)

### File List
(待开发时填写)

## QA Results
(待QA测试时填写)