# Story 3.6: 多方案决策支持系统实现

## Status
Draft

## Story

**As a** 应急决策者,
**I want** 一个智能的多方案决策支持系统,
**so that** 能够基于E-Agent生成的多个方案进行科学决策，获得最优的应急响应策略。

## Acceptance Criteria

1. 决策支持系统能够接收和处理多个执行方案
2. 提供多维度的方案对比分析功能
3. 实现智能的决策建议生成算法
4. 支持决策者自定义决策权重和偏好
5. 输出详细的决策依据和选择建议

## Tasks / Subtasks

- [ ] 实现方案对比分析引擎 (AC: #1)
  - [ ] 设计多维度评估框架
    - [ ] 效果评估维度
    - [ ] 效率评估维度
    - [ ] 风险评估维度
    - [ ] 成本评估维度
  - [ ] 实现对比分析算法
    - [ ] 标准化处理算法
    - [ ] 权重分配算法
    - [ ] 综合评分计算
    - [ ] 排序算法
  - [ ] 创建敏感性分析器
    - [ ] 参数敏感性测试
    - [ ] 结果稳定性分析
    - [ ] 敏感性报告生成
    - [ ] 风险阈值分析
  - [ ] 实现优势劣势分析
    - [ ] 方案优势识别
    - [ ] 方案劣势分析
    - [ ] 差异化特征提取
    - [ ] 竞争力评估
  - [ ] 设计可视化对比组件
    - [ ] 雷达图对比
    - [ ] 柱状图对比
    - [ ] 热力图展示
    - [ ] 交互式对比界面

- [ ] 实现智能决策建议引擎 (AC: #2)
  - [ ] 设计决策模型框架
    - [ ] 多标准决策模型
    - [ ] 层次分析法模型
    - [ ] 模糊综合评价模型
    - [ ] 机器学习决策模型
  - [ ] 实现决策权重管理
    - [ ] 权重配置接口
    - [ ] 动态权重调整
    - [ ] 权重敏感性分析
    - [ ] 权重验证机制
  - [ ] 创建推荐算法引擎
    - [ ] 推荐算法选择器
    - [ ] 算法参数优化
    - [ ] 推荐结果验证
    - [ ] 算法性能评估
  - [ ] 实现决策依据生成
    - [ ] 推理过程追踪
    - [ ] 证据链构建
    - [ ] 逻辑验证器
    - [ ] 解释生成器
  - [ ] 设计决策风险评估
    - [ ] 决策风险识别
    - [ ] 风险概率计算
    - [ ] 风险影响评估
    - [ ] 风险缓解建议

- [ ] 实现用户偏好管理系统 (AC: #3)
  - [ ] 设计偏好配置框架
    - [ ] 偏好维度定义
    - [ ] 偏好量化方法
    - [ ] 偏好存储机制
    - [ ] 偏好版本管理
  - [ ] 实现偏好学习算法
    - [ ] 历史决策分析
    - [ ] 偏好模式识别
    - [ ] 偏好预测模型
    - [ ] 偏好自适应调整
  - [ ] 创建个性化推荐
    - [ ] 个性化权重计算
    - [ ] 个性化评分算法
    - [ ] 个性化推荐生成
    - [ ] 个性化解释生成
  - [ ] 实现偏好验证机制
    - [ ] 偏好一致性检查
    - [ ] 偏好合理性验证
    - [ ] 偏好冲突检测
    - [ ] 偏好调整建议
  - [ ] 设计偏好可视化
    - [ ] 偏好雷达图
    - [ ] 偏好趋势图
    - [ ] 偏好对比图
    - [ ] 交互式调整界面

- [ ] 实现决策质量保证 (AC: #4)
  - [ ] 设计质量评估体系
    - [ ] 决策合理性评估
    - [ ] 决策一致性评估
    - [ ] 决策稳定性评估
    - [ ] 决策满意度评估
  - [ ] 实现决策验证机制
    - [ ] 逻辑一致性验证
    - [ ] 数据准确性验证
    - [ ] 算法正确性验证
    - [ ] 结果可靠性验证
  - [ ] 创建决策反馈系统
    - [ ] 决策执行跟踪
    - [ ] 效果反馈收集
    - [ ] 满意度调查
    - [ ] 改进建议收集
  - [ ] 实现决策学习机制
    - [ ] 决策案例学习
    - [ ] 模型参数优化
    - [ ] 算法性能提升
    - [ ] 知识库更新
  - [ ] 设计质量监控面板
    - [ ] 质量指标展示
    - [ ] 趋势分析图表
    - [ ] 异常预警提示
    - [ ] 改进建议显示

- [ ] 实现决策输出系统 (AC: #5)
  - [ ] 设计决策数据模型
    - [ ] DecisionSupport决策支持结构
    - [ ] PlanComparison方案对比结构
    - [ ] DecisionRecommendation决策建议结构
    - [ ] DecisionRationale决策依据结构
  - [ ] 实现结构化输出
    - [ ] JSON格式输出
    - [ ] XML格式支持
    - [ ] 决策报告格式
    - [ ] 自定义格式扩展
  - [ ] 创建决策报告生成器
    - [ ] 报告模板管理
    - [ ] 内容自动填充
    - [ ] 图表自动生成
    - [ ] 报告质量控制
  - [ ] 实现交互式决策界面
    - [ ] 方案对比界面
    - [ ] 参数调整界面
    - [ ] 权重设置界面
    - [ ] 实时预览功能
  - [ ] 设计决策记录系统
    - [ ] 决策历史记录
    - [ ] 决策审计日志
    - [ ] 决策统计分析
    - [ ] 决策知识提取

## Dev Notes

### 技术要点
- 采用多标准决策分析(MCDA)算法进行方案对比
- 实现用户偏好学习和个性化推荐机制
- 提供敏感性分析和稳定性评估功能
- 构建可视化的决策支持界面
- 支持实时决策调整和方案优化

### 核心功能模块
- **方案对比分析器**: 多维度对比不同执行方案
- **决策建议引擎**: 基于算法生成智能决策建议
- **用户偏好管理器**: 学习和管理用户决策偏好
- **敏感性分析器**: 分析决策结果的稳定性
- **可视化展示器**: 提供直观的决策支持界面

### 决策准则体系
- **有效性**: 方案达到预期目标的程度
- **效率性**: 资源利用和时间效率
- **风险性**: 方案执行的风险水平
- **成本**: 经济成本和资源消耗
- **可行性**: 技术和操作可行性
- **及时性**: 响应时间和执行时效
- **可持续性**: 长期影响和持续效果
- **可接受性**: 利益相关者的接受程度

### 决策支持流程
1. 接收E-Agent生成的多个执行方案
2. 获取或学习用户决策偏好
3. 确定决策准则和权重配置
4. 执行多维度方案对比分析
5. 进行敏感性分析和稳定性评估
6. 使用多种决策算法生成建议
7. 集成结果并生成决策依据

### 依赖关系
- 依赖Story 3.5 E-Agent生成的执行方案
- 需要与用户交互获取偏好反馈
- 为决策者提供科学的决策依据
- 持续学习优化决策质量

### Testing

#### 测试标准

class MultiPlanDecisionSupportSystem:
    """多方案决策支持系统"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config

        # 方案对比组件
        self.comparison_engine = ComparisonEngine()
        self.criterion_evaluator = CriterionEvaluator()
        self.sensitivity_analyzer = SensitivityAnalyzer()

        # 决策算法组件
        self.ahp_processor = AHPProcessor()
        self.topsis_processor = TOPSISProcessor()
        self.electre_processor = ELECTREProcessor()
        self.ensemble_method = EnsembleMethod()

        # 用户偏好组件
        self.preference_manager = PreferenceManager()
        self.preference_learner = PreferenceLearner()
        self.personalization_engine = PersonalizationEngine()

        # 决策建议组件
        self.recommendation_engine = RecommendationEngine()
        self.rationale_generator = RationaleGenerator()
        self.confidence_estimator = ConfidenceEstimator()

        # 质量保证组件
        self.quality_assessor = QualityAssessor()
        self.validation_engine = ValidationEngine()
        self.feedback_processor = FeedbackProcessor()

    async def generate_decision_support(self,
                                      execution_plans: List[Dict[str, Any]],
                                      user_id: Optional[str] = None,
                                      decision_criteria: Optional[List[DecisionCriterion]] = None,
                                      preferences: Optional[UserPreference] = None) -> DecisionSupportResult:
        """生成决策支持"""
        start_time = time.time()

        try:
            # 步骤1: 获取或创建用户偏好
            if preferences is None and user_id:
                preferences = await self.preference_manager.get_user_preferences(user_id)
                if preferences is None:
                    preferences = await self._create_default_preferences(user_id)

            # 步骤2: 确定决策准则
            if decision_criteria is None:
                decision_criteria = await self._determine_decision_criteria(
                    execution_plans, preferences
                )

            # 步骤3: 方案对比分析
            comparison_result = await self.comparison_engine.compare_plans(
                execution_plans, decision_criteria, preferences
            )

            # 步骤4: 敏感性分析
            sensitivity_analysis = await self.sensitivity_analyzer.analyze_sensitivity(
                execution_plans, decision_criteria, preferences
            )
            comparison_result.sensitivity_analysis = sensitivity_analysis

            # 步骤5: 生成决策建议
            recommendation = await self.recommendation_engine.generate_recommendation(
                comparison_result, preferences, decision_criteria
            )

            # 步骤6: 质量评估
            decision_quality = await self.quality_assessor.assess_decision_quality(
                comparison_result, recommendation
            )

            # 步骤7: 满意度预测
            satisfaction_prediction = await self._predict_satisfaction(
                recommendation, preferences
            )

            result = DecisionSupportResult(
                support_id=f"decision_support_{int(time.time())}",
                scenario_id=execution_plans[0].get('scenario_id') if execution_plans else "",
                user_id=user_id or "anonymous",
                generation_timestamp=datetime.now(),
                execution_plans=execution_plans,
                user_preferences=preferences,
                decision_criteria=decision_criteria,
                comparison_result=comparison_result,
                recommendation=recommendation,
                decision_quality=decision_quality,
                satisfaction_prediction=satisfaction_prediction,
                feedback_data={},
                improvement_suggestions=await self._generate_improvement_suggestions(
                    comparison_result, recommendation
                )
            )

            # 记录决策支持日志
            await self._log_decision_support(result)

            return result

        except Exception as e:
            logger.error(f"Decision support generation failed: {e}")
            raise

    async def update_user_preferences(self, user_id: str,
                                    preference_updates: Dict[str, Any]) -> bool:
        """更新用户偏好"""
        try:
            # 获取当前偏好
            current_preferences = await self.preference_manager.get_user_preferences(user_id)

            if current_preferences is None:
                current_preferences = await self._create_default_preferences(user_id)

            # 应用更新
            updated_preferences = await self.preference_learner.update_preferences(
                current_preferences, preference_updates
            )

            # 保存更新后的偏好
            success = await self.preference_manager.save_user_preferences(
                user_id, updated_preferences
            )

            if success:
                logger.info(f"User preferences updated for user {user_id}")
            else:
                logger.error(f"Failed to update preferences for user {user_id}")

            return success

        except Exception as e:
            logger.error(f"Failed to update user preferences: {e}")
            return False

    async def collect_feedback(self, support_id: str,
                             user_feedback: Dict[str, Any]) -> bool:
        """收集用户反馈"""
        try:
            # 处理反馈数据
            processed_feedback = await self.feedback_processor.process_feedback(
                support_id, user_feedback
            )

            # 更新学习数据
            await self.preference_learner.learn_from_feedback(processed_feedback)

            # 优化模型参数
            await self._optimize_models(processed_feedback)

            logger.info(f"Feedback collected for decision support {support_id}")
            return True

        except Exception as e:
            logger.error(f"Failed to collect feedback: {e}")
            return False

class ComparisonEngine:
    """方案对比引擎"""

    def __init__(self):
        self.normalizer = MinMaxScaler()
        self.weight_calculator = WeightCalculator()
        self.score_aggregator = ScoreAggregator()

    async def compare_plans(self,
                          execution_plans: List[Dict[str, Any]],
                          decision_criteria: List[DecisionCriterion],
                          user_preferences: UserPreference) -> PlanComparisonResult:
        """对比方案"""
        try:
            # 提取方案评估数据
            plan_evaluations = await self._extract_plan_evaluations(execution_plans)

            # 标准化评估数据
            normalized_evaluations = await self._normalize_evaluations(plan_evaluations)

            # 应用用户权重
            weighted_evaluations = await self._apply_user_weights(
                normalized_evaluations, user_preferences, decision_criteria
            )

            # 计算综合评分
            plan_scores = await self.score_aggregator.aggregate_scores(
                weighted_evaluations, decision_criteria
            )

            # 生成方案排名
            ranking = sorted(plan_scores.items(), key=lambda x: x[1], reverse=True)

            # 分析优劣势
            advantages, disadvantages = await self._analyze_advantages_disadvantages(
                weighted_evaluations, decision_criteria
            )

            # 分析权衡关系
            trade_offs = await self._analyze_trade_offs(
                weighted_evaluations, decision_criteria
            )

            return PlanComparisonResult(
                comparison_id=f"comparison_{int(time.time())}",
                comparison_timestamp=datetime.now(),
                compared_plans=[plan.get('plan_id') for plan in execution_plans],
                plan_scores=plan_scores,
                criterion_scores=weighted_evaluations,
                ranking=[plan_id for plan_id, _ in ranking],
                advantages=advantages,
                disadvantages=disadvantages,
                trade_offs=trade_offs,
                sensitivity_analysis={},
                stability_analysis={}
            )

        except Exception as e:
            logger.error(f"Plan comparison failed: {e}")
            raise

    async def _extract_plan_evaluations(self, execution_plans: List[Dict[str, Any]]) -> Dict[str, Dict[str, float]]:
        """提取方案评估数据"""
        try:
            evaluations = {}

            for plan in execution_plans:
                plan_id = plan.get('plan_id')
                evaluations[plan_id] = {
                    DecisionCriterion.EFFECTIVENESS.value: plan.get('effectiveness_score', 0.0),
                    DecisionCriterion.EFFICIENCY.value: plan.get('efficiency_score', 0.0),
                    DecisionCriterion.RISK.value: 1.0 - plan.get('risk_level', 0.5),  # 风险转换为收益
                    DecisionCriterion.COST.value: 1.0 - self._normalize_cost(plan.get('estimated_cost', {})),
                    DecisionCriterion.FEASIBILITY.value: plan.get('feasibility_score', 0.0)
                }

            return evaluations

        except Exception as e:
            logger.error(f"Failed to extract plan evaluations: {e}")
            raise

class RecommendationEngine:
    """决策建议引擎"""

    def __init__(self):
        self.decision_methods = {
            DecisionMethod.AHP: AHPProcessor(),
            DecisionMethod.TOPSIS: TOPSISProcessor(),
            DecisionMethod.ELECTRE: ELECTREProcessor()
        }
        self.ensemble_method = EnsembleMethod()
        self.rationale_generator = RationaleGenerator()

    async def generate_recommendation(self,
                                    comparison_result: PlanComparisonResult,
                                    user_preferences: UserPreference,
                                    decision_criteria: List[DecisionCriterion]) -> DecisionRecommendation:
        """生成决策建议"""
        try:
            # 选择最佳决策方法
            best_method = await self._select_best_decision_method(
                comparison_result, user_preferences
            )

            # 使用选定的方法生成建议
            method_result = await self.decision_methods[best_method].generate_recommendation(
                comparison_result, user_preferences, decision_criteria
            )

            # 集成多个方法的结果
            ensemble_result = await self.ensemble_method.ensemble_recommendations(
                [method_result], comparison_result
            )

            # 生成决策依据
            rationale = await self.rationale_generator.generate_rationale(
                ensemble_result, comparison_result, user_preferences
            )

            # 评估建议置信度
            confidence_level = await self._calculate_confidence_level(
                ensemble_result, comparison_result
            )

            # 识别决策风险
            decision_risks = await self._identify_decision_risks(
                ensemble_result, comparison_result
            )

            # 生成风险缓解措施
            risk_mitigation = await self._generate_risk_mitigation(decision_risks)

            return DecisionRecommendation(
                recommendation_id=f"recommendation_{int(time.time())}",
                scenario_id=comparison_result.compared_plans[0] if comparison_result.compared_plans else "",
                recommendation_timestamp=datetime.now(),
                recommended_plan=ensemble_result['recommended_plan'],
                alternative_plans=ensemble_result['alternative_plans'],
                confidence_level=confidence_level,
                decision_rationale=rationale,
                key_factors=ensemble_result['key_factors'],
                supporting_evidence=ensemble_result['supporting_evidence'],
                decision_risks=decision_risks,
                risk_mitigation=risk_mitigation,
                implementation_notes=await self._generate_implementation_notes(ensemble_result),
                monitoring_requirements=await self._generate_monitoring_requirements(ensemble_result),
                success_indicators=await self._generate_success_indicators(ensemble_result),
                decision_method=best_method,
                user_preferences_applied=True,
                quality_score=await self._assess_recommendation_quality(ensemble_result)
            )

        except Exception as e:
            logger.error(f"Failed to generate recommendation: {e}")
            raise

class PreferenceLearner:
    """偏好学习器"""

    def __init__(self):
        self.learning_algorithms = {
            'explicit_feedback': ExplicitFeedbackLearner(),
            'implicit_feedback': ImplicitFeedbackLearner(),
            'collaborative_filtering': CollaborativeFilteringLearner()
        }
        self.preference_model = PreferenceModel()

    async def update_preferences(self,
                               current_preferences: UserPreference,
                               preference_updates: Dict[str, Any]) -> UserPreference:
        """更新用户偏好"""
        try:
            # 分析更新类型
            update_type = self._classify_update_type(preference_updates)

            # 选择学习算法
            learner = self.learning_algorithms.get(update_type)

            if learner:
                # 应用学习算法
                learned_preferences = await learner.learn_preferences(
                    current_preferences, preference_updates
                )
            else:
                # 直接应用更新
                learned_preferences = await self._apply_direct_updates(
                    current_preferences, preference_updates
                )

            # 验证偏好一致性
            validated_preferences = await self._validate_preference_consistency(
                learned_preferences
            )

            # 更新时间戳
            validated_preferences.updated_at = datetime.now()

            return validated_preferences

        except Exception as e:
            logger.error(f"Failed to update preferences: {e}")
            return current_preferences

    async def learn_from_feedback(self, feedback_data: Dict[str, Any]) -> None:
        """从反馈中学习"""
        try:
            # 提取学习样本
            learning_samples = await self._extract_learning_samples(feedback_data)

            # 更新偏好模型
            await self.preference_model.update_model(learning_samples)

            # 优化模型参数
            await self._optimize_model_parameters()

            logger.info("Learning from feedback completed")

        except Exception as e:
            logger.error(f"Failed to learn from feedback: {e}")

class QualityAssessor:
    """质量评估器"""

    def __init__(self):
        self.quality_metrics = {
            'consistency': ConsistencyMetric(),
            'reliability': ReliabilityMetric(),
            'transparency': TransparencyMetric(),
            'actionability': ActionabilityMetric()
        }

    async def assess_decision_quality(self,
                                    comparison_result: PlanComparisonResult,
                                    recommendation: DecisionRecommendation) -> Dict[str, float]:
        """评估决策质量"""
        try:
            quality_scores = {}

            # 一致性评估
            consistency_score = await self.quality_metrics['consistency'].assess(
                comparison_result, recommendation
            )
            quality_scores['consistency'] = consistency_score

            # 可靠性评估
            reliability_score = await self.quality_metrics['reliability'].assess(
                comparison_result, recommendation
            )
            quality_scores['reliability'] = reliability_score

            # 透明性评估
            transparency_score = await self.quality_metrics['transparency'].assess(
                comparison_result, recommendation
            )
            quality_scores['transparency'] = transparency_score

            # 可操作性评估
            actionability_score = await self.quality_metrics['actionability'].assess(
                comparison_result, recommendation
            )
            quality_scores['actionability'] = actionability_score

            # 综合质量评分
            overall_quality = np.mean(list(quality_scores.values()))
            quality_scores['overall'] = overall_quality

            return quality_scores

        except Exception as e:
            logger.error(f"Failed to assess decision quality: {e}")
            return {'overall': 0.5}
```

### 开发工作流程
1. 接收E-Agent生成的多个执行方案
2. 获取或学习用户决策偏好
3. 确定决策准则和权重配置
4. 执行多维度方案对比分析
5. 进行敏感性分析和稳定性评估
6. 使用多种决策算法生成建议
7. 集成结果并生成决策依据
8. 评估决策质量和风险
9. 输出结构化的决策支持结果

### 依赖关系说明
- 依赖Story 3.5 E-Agent生成的执行方案
- 需要与用户交互获取偏好反馈
- 为决策者提供科学的决策依据
- 持续学习优化决策质量

### 重要注意事项
- 决策算法需要考虑用户主观偏好
- 方案对比需要全面和客观
- 决策建议需要充分的可解释性
- 质量评估需要多维度指标
- 用户反馈需要及时处理和学习

### 测试策略
- 单元测试: 测试各个决策算法的正确性
- 集成测试: 测试完整的决策支持流程
- 用户测试: 邀请用户评估系统效果
- 性能测试: 测试大规模方案的处理能力

### Testing

#### 测试标准
- 测试文件位置: tests/decision_support/目录
- 方案对比测试: 验证对比分析的正确性
- 决策算法测试: 验证各种决策算法的效果
- 偏好学习测试: 验证偏好学习的准确性
- 质量评估测试: 验证质量评估的可靠性

#### 测试框架和模式
- 单元测试: pytest + 决策算法测试工具
- 集成测试: pytest + 模拟决策场景
- 用户测试: A/B测试 + 用户满意度调查
- 性能测试: pytest + 负载测试

#### 特定测试要求
- 多种决策算法的一致性测试
- 用户偏好学习的准确性测试
- 决策建议的可解释性测试
- 敏感性分析的稳定性测试
- 不同场景下的适应性测试

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-10-20 | 1.0 | 初始故事创建 | John (PM) |

## Dev Agent Record

### Agent Model Used
(待开发时填写)

### Debug Log References
(待开发时填写)

### Completion Notes List
(待开发时填写)

### File List
(待开发时填写)

## QA Results
(待QA测试时填写)