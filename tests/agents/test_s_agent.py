#!/usr/bin/env python3
"""
S-Agent æµ‹è¯•è„šæœ¬
æµ‹è¯•S-Agentçš„æ ¸å¿ƒåŠŸèƒ½å’Œé›†æˆ
"""

import asyncio
import json
import logging
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def create_test_scenario() -> dict:
    """åˆ›å»ºæµ‹è¯•åœºæ™¯"""
    return {
        "event_id": "TEST_FLOOD_001",
        "event_type": "flood",
        "severity_level": "high",
        "description": "åŸå¸‚åŒºåŸŸå‘ç”Ÿä¸¥é‡æ´ªæ°´ï¼Œå½±å“èŒƒå›´è¾ƒå¤§",
        "location": {
            "address": "æŸå¸‚æŸåŒºä¸»è¦è¡—é“",
            "coordinates": {"lat": 39.9042, "lng": 116.4074},
            "region": "å¸‚ä¸­å¿ƒ",
            "affected_regions": ["ä¸œåŒº", "è¥¿åŒº", "å—åŒº"],
            "population_density": "high"
        },
        "event_time": datetime.now().isoformat(),
        "report_time": datetime.now().isoformat(),
        "response_window": 3600,
        "urgency_level": "urgent",
        "environment": {
            "weather": {"condition": "heavy_rain", "visibility": "poor"},
            "terrain": "urban",
            "accessibility": "difficult",
            "temperature": "20Â°C",
            "humidity": "95%"
        },
        "impact": {
            "radius_km": 5.0,
            "population_affected": 5000,
            "infrastructure_damage": {
                "roads": "partially_flooded",
                "buildings": "ground_floors_affected",
                "utilities": "power_outages"
            },
            "level": 3
        },
        "risk_factors": [
            {
                "type": "drowning",
                "level": 4,
                "description": "æ´ªæ°´æ·¹æ²¡åŒºåŸŸå­˜åœ¨æººæ°´é£é™©",
                "time_sensitivity": "critical",
                "mitigation_difficulty": "high"
            },
            {
                "type": "infrastructure_failure",
                "level": 3,
                "description": "åŸºç¡€è®¾æ–½å¯èƒ½è¿›ä¸€æ­¥æŸå",
                "time_sensitivity": "high",
                "mitigation_difficulty": "medium"
            },
            {
                "type": "disease_outbreak",
                "level": 2,
                "description": "æ´ªæ°´åå¯èƒ½çˆ†å‘ç–«æƒ…",
                "time_sensitivity": "medium",
                "mitigation_difficulty": "medium"
            }
        ]
    }


def create_s_agent_config() -> dict:
    """åˆ›å»ºS-Agenté…ç½®"""
    return {
        "agent_id": "s_agent_test_001",
        "name": "æµ‹è¯•æˆ˜ç•¥åè°ƒå®˜",
        "llm_config": {
            "provider": "deepseek",
            "model": "deepseek-chat",
            "api_key": "test_key",  # æµ‹è¯•ç”¨
            "base_url": "https://api.deepseek.com/v1",
            "temperature": 0.7,
            "max_tokens": 2000
        },
        "scenario_parser": {
            "validation_enabled": True,
            "enhanced_analysis": True
        },
        "strategic_analyzer": {
            "priority_weights": {
                "life_safety": 0.4,
                "infrastructure": 0.2,
                "environment": 0.15,
                "economy": 0.15,
                "social_stability": 0.1
            }
        },
        "priority_evaluator": {
            "priority_weights": {
                "life_safety": 0.35,
                "time_sensitivity": 0.25,
                "resource_availability": 0.15,
                "impact_scope": 0.15,
                "feasibility": 0.10
            }
        },
        "output_manager": {
            "output_formats": ["json", "yaml"],
            "version": "1.0"
        }
    }


async def test_scenario_parser():
    """æµ‹è¯•åœºæ™¯è§£æå™¨"""
    logger.info("=== æµ‹è¯•åœºæ™¯è§£æå™¨ ===")

    try:
        from core.agents.strategist.scenario_parser import ScenarioParser

        parser = ScenarioParser()
        scenario_data = create_test_scenario()

        # è§£æåœºæ™¯
        scenario_info = await parser.parse_scenario(scenario_data)

        logger.info(f"åœºæ™¯è§£ææˆåŠŸ: {scenario_info.scenario_id}")
        logger.info(f"äº‹ä»¶ç±»å‹: {scenario_info.event_type}")
        logger.info(f"ä¸¥é‡ç¨‹åº¦: {scenario_info.severity_level}")
        logger.info(f"å—å½±å“äººå£: {scenario_info.impact_assessment.get('population_affected', 0)}")
        logger.info(f"é£é™©å› ç´ æ•°é‡: {len(scenario_info.risk_factors)}")

        # éªŒè¯åœºæ™¯
        is_valid, errors = await parser.validate_scenario(scenario_info)
        logger.info(f"åœºæ™¯éªŒè¯ç»“æœ: {'é€šè¿‡' if is_valid else 'å¤±è´¥'}")
        if errors:
            logger.warning(f"éªŒè¯é”™è¯¯: {errors}")

        return scenario_info

    except Exception as e:
        logger.error(f"åœºæ™¯è§£æå™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        return None


async def test_strategic_analyzer(scenario_info):
    """æµ‹è¯•æˆ˜ç•¥åˆ†æå™¨"""
    logger.info("=== æµ‹è¯•æˆ˜ç•¥åˆ†æå™¨ ===")

    try:
        from core.agents.strategist.strategic_analyzer import StrategicAnalyzer

        analyzer = StrategicAnalyzer()

        # ç”Ÿæˆæˆ˜ç•¥æ¡†æ¶
        strategic_framework = await analyzer.analyze_and_generate_framework(scenario_info)

        logger.info(f"æˆ˜ç•¥æ¡†æ¶ç”ŸæˆæˆåŠŸ: {strategic_framework.framework_id}")
        logger.info(f"æˆ˜ç•¥ç›®æ ‡æ•°é‡: {len(strategic_framework.strategic_goals)}")
        logger.info(f"å†³ç­–ç‚¹æ•°é‡: {len(strategic_framework.decision_points)}")
        logger.info(f"è¡ŒåŠ¨ä¼˜å…ˆçº§æ•°é‡: {len(strategic_framework.action_priorities)}")

        # æ˜¾ç¤ºå‰3ä¸ªæˆ˜ç•¥ç›®æ ‡
        for i, goal in enumerate(strategic_framework.strategic_goals[:3]):
            logger.info(f"ç›®æ ‡ {i+1}: {goal.title} (ä¼˜å…ˆçº§: {goal.priority})")

        return strategic_framework

    except Exception as e:
        logger.error(f"æˆ˜ç•¥åˆ†æå™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        return None


async def test_priority_evaluator(scenario_info, strategic_framework):
    """æµ‹è¯•ä¼˜å…ˆçº§è¯„ä¼°å™¨"""
    logger.info("=== æµ‹è¯•ä¼˜å…ˆçº§è¯„ä¼°å™¨ ===")

    try:
        from core.agents.strategist.priority_evaluator import PriorityEvaluator

        evaluator = PriorityEvaluator()

        # æå–åŸºç¡€è¡ŒåŠ¨
        base_actions = []
        for goal in strategic_framework.strategic_goals:
            action = {
                'action_id': f"ACT_{goal.goal_id}",
                'title': goal.title,
                'description': goal.description,
                'category': 'life_safety' if 'ç”Ÿå‘½' in goal.title else 'infrastructure',
                'priority': goal.priority,
                'estimated_duration': '2-4 hours',
                'resource_requirements': {'personnel': 5, 'equipment': 'basic'},
                'dependencies': [],
                'complexity': 'medium',
                'scope': 'city'
            }
            base_actions.append(action)

        # è¯„ä¼°ä¼˜å…ˆçº§
        evaluated_actions = await evaluator.evaluate_priorities(
            scenario_info, strategic_framework, base_actions
        )

        logger.info(f"ä¼˜å…ˆçº§è¯„ä¼°å®Œæˆï¼Œå…±è¯„ä¼° {len(evaluated_actions)} ä¸ªè¡ŒåŠ¨")

        # æ˜¾ç¤ºå‰5ä¸ªé«˜ä¼˜å…ˆçº§è¡ŒåŠ¨
        for i, action in enumerate(evaluated_actions[:5]):
            logger.info(f"è¡ŒåŠ¨ {i+1}: {action['title']} (è¯„åˆ†: {action['priority_score'].score:.1f})")

        # ç”Ÿæˆä¼˜å…ˆçº§çŸ©é˜µ
        priority_matrix = await evaluator.generate_priority_matrix(evaluated_actions)
        logger.info(f"ä¼˜å…ˆçº§çŸ©é˜µç”ŸæˆæˆåŠŸ")
        logger.info(f"å…³é”®è¡ŒåŠ¨æ•°é‡: {priority_matrix['summary']['critical_actions']}")

        return evaluated_actions, priority_matrix

    except Exception as e:
        logger.error(f"ä¼˜å…ˆçº§è¯„ä¼°å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        return [], {}


async def test_output_manager(scenario_info, strategic_framework, evaluated_actions, priority_matrix):
    """æµ‹è¯•è¾“å‡ºç®¡ç†å™¨"""
    logger.info("=== æµ‹è¯•è¾“å‡ºç®¡ç†å™¨ ===")

    try:
        from core.agents.strategist.output_manager import OutputManager

        manager = OutputManager()

        # ç”Ÿæˆå®Œæ•´è¾“å‡º
        output = await manager.generate_strategic_output(
            scenario_info, strategic_framework, evaluated_actions, priority_matrix
        )

        logger.info(f"æˆ˜ç•¥è¾“å‡ºç”ŸæˆæˆåŠŸ: {output['metadata']['output_id']}")
        logger.info(f"è¾“å‡ºç‰ˆæœ¬: {output['metadata']['version']}")
        logger.info(f"åˆ†ç±»çº§åˆ«: {output['metadata']['classification']}")

        # æ˜¾ç¤ºå…³é”®ç»Ÿè®¡
        action_summary = output['action_priorities']['summary']
        logger.info(f"è¡ŒåŠ¨åˆ†å¸ƒ - å…³é”®: {action_summary['critical_count']}, "
                   f"é«˜: {action_summary['high_count']}, "
                   f"ä¸­: {action_summary['medium_count']}, "
                   f"ä½: {action_summary['low_count']}")

        # æ˜¾ç¤ºæ‰§è¡Œè®¡åˆ’
        execution_plan = output['execution_plan']
        logger.info(f"æ‰§è¡Œè®¡åˆ’åŒ…å« {len(execution_plan['phases'])} ä¸ªé˜¶æ®µ")
        logger.info(f"æ€»é¢„è®¡æ—¶é•¿: {execution_plan['total_duration']}")

        # å¯¼å‡ºä¸ºJSON
        exported = await manager.export_to_formats(output)
        if 'json' in exported:
            # ä¿å­˜åˆ°æ–‡ä»¶
            output_file = Path("test_s_agent_output.json")
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(exported['json'])
            logger.info(f"è¾“å‡ºå·²ä¿å­˜åˆ°: {output_file}")

        return output

    except Exception as e:
        logger.error(f"è¾“å‡ºç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        return None


async def test_s_agent_integration():
    """æµ‹è¯•S-Agentå®Œæ•´é›†æˆ"""
    logger.info("=== æµ‹è¯•S-Agentå®Œæ•´é›†æˆ ===")

    try:
        from core.agents.strategist.s_agent import StrategistAgent

        # åˆ›å»ºS-Agent
        config = create_s_agent_config()
        agent = StrategistAgent(config)

        # åˆå§‹åŒ–
        init_success = await agent.initialize()
        if not init_success:
            logger.error("S-Agentåˆå§‹åŒ–å¤±è´¥")
            return False

        logger.info("S-Agentåˆå§‹åŒ–æˆåŠŸ")

        # æ‰§è¡Œåœºæ™¯åˆ†æ
        scenario_data = create_test_scenario()
        result = await agent.analyze_scenario(scenario_data)

        if result['success']:
            logger.info("S-Agentåœºæ™¯åˆ†ææˆåŠŸ")
            logger.info(f"åˆ†æè€—æ—¶: {result['performance_metrics']['analysis_time']:.2f}ç§’")
            logger.info(f"ç”Ÿæˆè¡ŒåŠ¨æ•°é‡: {result['performance_metrics']['total_actions']}")
            logger.info(f"æˆ˜ç•¥ç›®æ ‡æ•°é‡: {result['performance_metrics']['strategic_goals']}")

            # è·å–AgentçŠ¶æ€
            status = agent.get_status()
            logger.info(f"AgentçŠ¶æ€: {status['status']}")
            logger.info(f"æ€»åˆ†ææ¬¡æ•°: {status['performance_metrics']['total_analyses']}")

            return True
        else:
            logger.error(f"S-Agentåœºæ™¯åˆ†æå¤±è´¥: {result.get('error', 'Unknown error')}")
            return False

    except Exception as e:
        logger.error(f"S-Agenté›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
        return False


async def test_strategy_optimizer():
    """æµ‹è¯•æˆ˜ç•¥ä¼˜åŒ–å™¨"""
    logger.info("=== æµ‹è¯•æˆ˜ç•¥ä¼˜åŒ–å™¨ ===")

    try:
        from core.agents.strategist.strategy_optimizer import (
            StrategyOptimizer, FeedbackData
        )

        optimizer = StrategyOptimizer()

        # æ¨¡æ‹Ÿå½“å‰æˆ˜ç•¥
        current_strategy = {
            "strategy_id": "TEST_STRATEGY_001",
            "strategic_goals": [
                {"goal_id": "GOAL_001", "title": "ä¿éšœç”Ÿå‘½å®‰å…¨", "priority": 10},
                {"goal_id": "GOAL_002", "title": "æ§åˆ¶æ´ªæ°´", "priority": 8}
            ],
            "action_priorities": {"total_actions": 5},
            "resource_allocation": {"personnel": "adequate"}
        }

        # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®
        performance_data = {
            "success_rate": 75.0,
            "average_response_time": 35.0,
            "resource_efficiency": 70.0,
            "goal_completion_rate": 80.0
        }

        # æ¨¡æ‹Ÿåé¦ˆæ•°æ®
        feedback = FeedbackData(
            feedback_id="FB_001",
            strategy_id="TEST_STRATEGY_001",
            feedback_type="performance",
            content={
                "improvement_suggestion": "å¢åŠ æ•‘æ´äººå‘˜æ•°é‡",
                "summary": "èµ„æºä¸è¶³å½±å“å“åº”é€Ÿåº¦"
            },
            source="operator",
            timestamp=datetime.now().isoformat(),
            effectiveness_score=8.5
        )

        # æ‰§è¡Œä¼˜åŒ–
        scenario_info = create_test_scenario()
        scenario_info.scenario_id = "TEST_OPT_001"

        optimization_result = await optimizer.optimize_strategy(
            current_strategy, performance_data, [feedback], scenario_info
        )

        logger.info(f"æˆ˜ç•¥ä¼˜åŒ–æˆåŠŸ: {optimization_result.optimization_id}")
        logger.info(f"é¢„æœŸæ”¹è¿›æ•°é‡: {len(optimization_result.improvements)}")

        # æ˜¾ç¤ºä¼˜åŒ–ç»“æœæ‘˜è¦
        if 'optimization_metadata' in optimization_result.optimized_strategy:
            metadata = optimization_result.optimized_strategy['optimization_metadata']
            logger.info(f"ä¼˜åŒ–ç±»å‹: {metadata['optimization_type']}")
            logger.info(f"é¢„æœŸæ”¹è¿›: {metadata['expected_improvements']}")

        return True

    except Exception as e:
        logger.error(f"æˆ˜ç•¥ä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹S-AgentåŠŸèƒ½æµ‹è¯•")

    test_results = {}

    try:
        # 1. æµ‹è¯•åœºæ™¯è§£æå™¨
        scenario_info = await test_scenario_parser()
        test_results['scenario_parser'] = scenario_info is not None

        if not scenario_info:
            logger.error("åœºæ™¯è§£æå™¨æµ‹è¯•å¤±è´¥ï¼Œè·³è¿‡åç»­æµ‹è¯•")
            return

        # 2. æµ‹è¯•æˆ˜ç•¥åˆ†æå™¨
        strategic_framework = await test_strategic_analyzer(scenario_info)
        test_results['strategic_analyzer'] = strategic_framework is not None

        if not strategic_framework:
            logger.error("æˆ˜ç•¥åˆ†æå™¨æµ‹è¯•å¤±è´¥ï¼Œè·³è¿‡åç»­æµ‹è¯•")
            return

        # 3. æµ‹è¯•ä¼˜å…ˆçº§è¯„ä¼°å™¨
        evaluated_actions, priority_matrix = await test_priority_evaluator(
            scenario_info, strategic_framework
        )
        test_results['priority_evaluator'] = len(evaluated_actions) > 0

        # 4. æµ‹è¯•è¾“å‡ºç®¡ç†å™¨
        output = await test_output_manager(
            scenario_info, strategic_framework, evaluated_actions, priority_matrix
        )
        test_results['output_manager'] = output is not None

        # 5. æµ‹è¯•S-Agentå®Œæ•´é›†æˆ
        test_results['s_agent_integration'] = await test_s_agent_integration()

        # 6. æµ‹è¯•æˆ˜ç•¥ä¼˜åŒ–å™¨
        test_results['strategy_optimizer'] = await test_strategy_optimizer()

        # æ±‡æ€»æµ‹è¯•ç»“æœ
        logger.info("\n" + "="*50)
        logger.info("æµ‹è¯•ç»“æœæ±‡æ€»:")
        logger.info("="*50)

        total_tests = len(test_results)
        passed_tests = sum(test_results.values())

        for test_name, result in test_results.items():
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            logger.info(f"{test_name}: {status}")

        logger.info(f"\næ€»ä½“ç»“æœ: {passed_tests}/{total_tests} æµ‹è¯•é€šè¿‡")

        if passed_tests == total_tests:
            logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼S-Agentå®ç°æˆåŠŸï¼")
            return True
        else:
            logger.warning(f"âš ï¸ {total_tests - passed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤")
            return False

    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
        return False


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = asyncio.run(main())
    sys.exit(0 if success else 1)